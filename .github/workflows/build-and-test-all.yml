name: Build and test

on:
  schedule:
    - cron: |
        0 0 * * *
  push:
    paths:
      - ".github/workflows/build-and-test-all.yml"
      - "linux/*"
      - checkout-arrow.sh
      - s3-upload.py
      - build-binary-and-upload.R

jobs:
  setup:
    name: Identify commit and other parameters
    # The purpose of this step is to set the GitHub repository,
    # commit/ref to build, and the nightly version number to use.
    # This is done once up front so that later build stages can
    # all refer to the same parameters. See checkout-arrow.sh
    # for how these parameters are used.
    #
    # By default, this runs at 00:00 UTC, takes the latest commit
    # from apache/arrow, and calls it version x.y.z.YYYYMMDD,
    # where YYYYMMDD is yesterday's date (i.e. the date that should
    # correspond to the commit, assuming there are commits every day).
    #
    # At CRAN release time, you may want to run a version of this
    # to build just the Linux C++ binaries corresponding to the
    # CRAN release. To do this, make a branch in this repository
    # and edit the "outputs" in this step: set `ref` to the
    # official release branch (or, if patches are required
    # after release, you may also need to specify a personal `fork`
    # and branch to build from), set `date` to "" to skip updating
    # the R version number, and set some of the downstream tasks
    # to `if: false` to skip building them.
    #
    # Similarly, if you want to test building artifacts from a branch,
    # specify the fork and ref, and you can set `date` to any number
    # you want. (I've used this to test building on r-hub Solaris VMs
    # with a custom C++ source package, for example.)
    runs-on: ubuntu-latest
    outputs:
      # To build from a different repo or branch, set these manually
      fork: apache
      # ref can be a branch name (but if not a fixed commit, beware:
      # it could change while the workflow is running)
      ref: apache-arrow-5.0.0
      # Set date to "" to skip updating the version string,
      # or set to an alternative value (e.g. 99999 to build a 3.0.0.99999)
      date: ""
    steps:
      - id: step0
        run: |
          FORK=apache
  linux-cpp:
    if: true
    needs: setup
    name: C++ Binary ${{ matrix.config.os }}-${{ matrix.config.version }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        config:
          - { os: ubuntu, version: "16.04" }
          - { os: ubuntu, version: "18.04" }
          - { os: debian, version: "9" }
          - { os: debian, version: "10" }
          - { os: centos, version: "7" }
          - { os: centos, version: "8" }
    env:
      VERSION: ${{ matrix.config.version }}
    steps:
      - name: Checkout arrow-r-nightly
        uses: actions/checkout@v2
      - name: Clone and configure arrow
        shell: bash
        env:
          FORK: ${{needs.setup.outputs.fork}}
          REF: ${{needs.setup.outputs.ref}}
          DATE: ${{needs.setup.outputs.date}}
        run: |
          cd linux
          source ../checkout-arrow.sh
      - name: Build
        shell: bash
        run: |
          cd linux
          docker-compose build ${{ matrix.config.os }}
          docker-compose run ${{ matrix.config.os }}
      - name: Set up Python (for S3 upload)
        uses: actions/setup-python@v2
        with:
          python-version: "3.x"
      - name: Install Boto
        run: |
          python -m pip install boto3
      - name: Bundle and upload
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        shell: bash
        run: |
          cd linux/arrow/r
          VERSION=$(grep ^Version DESCRIPTION | sed s/Version:\ //)
          export PKG_FILE="arrow-${VERSION}.zip"
          cd libarrow/dist
          # These files were created by the docker user so we have to sudo to get them
          sudo -E zip -r $PKG_FILE lib/ include/
          export REPO_PATH=/libarrow/bin/${{ matrix.config.os }}-${{ matrix.config.version }}
          # Or, upload to S3
          python ../../../../../s3-upload.py $PKG_FILE $REPO_PATH
